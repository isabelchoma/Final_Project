---
title: "README"
output:
 github_document:
 pandoc_args: ["--wrap=none"]
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
#Load the dataset
baseball_data <- read.csv('./Data/baseball_1985_2016.csv')

#Load necessary packages 
library(knitr)
library(ggplot2)
library(dplyr)
library(corrplot)
library(tidyr)
library(ggpubr)
library(stats)
library(car)
library(kableExtra)
#install.packages("ggcorrplot")  # if not already installed
library(ggcorrplot)
```

## Introduction 

As college students, we are constantly busy with classes, homeworks, and exams. We are all very involved in extracurricular activities outside of classes, which takes up a lot of time. However, in the free time that we do have, we love to get together with our friends and watch sports games. Whether it is the fall semester or the spring semester, there is always a sport being played (football in the fall, basketball in the winter, baseball in the spring). Since this project is being completed in the spring season, we decided to focus our attention on baseball. 

Specifically, we are interested in learning more about what influences a baseball player’s salary. Is it their batting average? Their experience? Their age? The team they play for? We will analyze these variables, plus many others, and how they influence a player’s salary. In this case, we are interested in assessing the following question: What best influences a hitters’ baseball player’s salary? 

To start, we will understand the data by reading literature about impacts on a baseball player’s salary. This will allow us to absorb the material we are trying to learn more about before actually starting to import and analyze the data into an open source data software. Then, we will provide some descriptive and numeric statistics of the dataset we collected. This will help provide an overview of the important features of the variables. Next, we will do some exploratory data analysis, analyzing any correlations between the independent variables of interest and the dependent variable. We will utilize plots and graphs to help us visualize the data. Finally, we will use machine learning models to see what the best way to identify patterns, make predictions, and improve its performance over time. 

We will calculate the batting average by dividing each player’s total hits per season by their total at-bat. This batting average is different because a hit is a batter reaching first base. It is a good starting point for evaluating a player’s offensive skills. A higher batting average suggests a batter is more consistent in making solid contact with the ball and getting on base via hits. 

## Data Organization

Data was collected using a website called Baseball Reference, which has baseball history and statistics for Major League Baseball. It is the complete source for current and historical baseball players, teams, scores, and leaders. Specifically, our dataset focuses on statistics from 1985, showing individuals’ performance, age, and other relevant information for a singular season. 

According to the Bureau Labor of Statistics, salary trends change over time. With free agencies and salary arbitration, salaries escalate. In addition, TV revenues fuel salary expansion, as the League has more money to work with. In order to understand how much a team can spend on its players, it is important to understand the distribution of their money. For the owners, player compensation looks like this: Major League Player Compensation + Benefit Plan Costs + Postseason Share Payments + Minor League Signing Bonuses (not including associated tax) + Minor League Salaries And Benefits. 
	
So, in order to comprehend the salary of an individual player, we must take this distribution into account. Salaries to the players themselves are comparable to salaries in the entertainment industry: star performers disproportionately earn higher amounts. These higher amounts are influenced by performance, seniority, and market size, with performance being the dominant factor. 

```{r, include=FALSE}
#Keeping only selected variables to evaluate
hitters_data <- baseball_data %>%
  select(playerid, yearid, hits_p, game_p, stint, atbat_b, hr_b, rbi_b, salary, birthyear)  

#Log salary to scale the data
hitters_data$log_Salary <- log(hitters_data$salary)

#Replace original salary data with logged salary
hitters_data <- hitters_data %>%
  filter(salary > 0) %>%
  mutate(salary = log(salary))

#Delete duplicate row of logged salary
hitters_data <- hitters_data[, -9]
```


After filtering the data by removing the irrelevant attributes to our analysis, these are the attributes included in our data, as well as their data type:

```{r, include=FALSE}
colnames(hitters_data) <- c("Player_ID", "Year_ID", "Hits", "Games Played", "Stint", "At Bat", "Homeruns", "RBI", "Birth Year", "Logged_Salary")

#Feature info table 
feature_info <- data.frame(
  Feature = colnames(hitters_data),
  Description = c("Player ID", "Year ID", "Number of hits per season", "Games played per season","How many years player has been on team", "Number of times at bat per season", "Home runs per season","Runs Batted In per season", "Birth Year", "Yearly salary in dollars, logged" 
  ),
  Scale_Type = c("Character", "Ordinal", "Interval", "Interval", "Interval", "Interval", "Interval", "Interval", "Interval", "Ratio"
  )
)
```


### Feature Descriptions for Baseball Data

```{r, echo=FALSE}
# Display the table nicely
kable(feature_info)
```

Some of the players in the dataset were pitchers and not hitters, so we had to remove rows with NA values for hits in order to only look at the hitters. 

```{r, echo=FALSE}
# Remove any NA or NaN value
hitters_data <- hitters_data[!is.na(hitters_data$Hits), ]

# Function to summarize data with key statistics, excluding Player_ID from summary only
get_summary_stats <- function(data) {
  data %>%
    select(where(is.numeric), -Year_ID) %>%  # keep only numeric vars, EXCEPT Year_ID
    summarise(across(
      everything(),
      list(
        Count = ~sum(!is.na(.)),
        Mean = ~mean(., na.rm = TRUE),
        Median = ~median(., na.rm = TRUE),
        SD = ~sd(., na.rm = TRUE),
        Min = ~min(., na.rm = TRUE),
        Max = ~max(., na.rm = TRUE)
      ),
      .names = "{.col}_{.fn}"
    )) %>%
    pivot_longer(
      cols = everything(),
      names_to = c("Variable", "Statistic"),
      names_pattern = "^(.*)_(Count|Mean|Median|SD|Min|Max)$",
      values_to = "Value"
    ) %>%
    pivot_wider(names_from = Statistic, values_from = Value)
}

# Summary Table
summary_baseball <- get_summary_stats(hitters_data)

kable(summary_baseball, caption = "Detailed Summary Statistics") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

```

## Exploratory Data Analysis

### Distribution of Variables 

```{r, echo=FALSE}
# Histogram for Hits
ggplot(hitters_data, aes(x = Hits)) +
  geom_histogram(binwidth = 10, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Hits", x = "Hits", y = "Frequency") +
  theme_minimal()

# Histogram for log_Salary
ggplot(hitters_data, aes(x = Logged_Salary)) +
  geom_histogram(binwidth = 0.1, fill = "lightgreen", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Logged Salary", x = "Log Salary", y = "Frequency") +
  theme_minimal()

# Histogram for Birth Year 
ggplot(hitters_data, aes(x = `Birth Year`)) +
  geom_histogram(binwidth = 10, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Birth Year", x = "Birth Year", y = "Frequency") +
  theme_minimal()

# Histogram for At Bat
ggplot(hitters_data, aes(x = `At Bat`)) +
  geom_histogram(binwidth = 10, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of At Bat", x = "At Bat", y = "Frequency") +
  theme_minimal()

# Density plot for Hits
ggplot(hitters_data, aes(x = Hits)) +
  geom_density(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Density of Hits", x = "Hits", y = "Density") +
  theme_minimal()

# Density plot for log_Salary
ggplot(hitters_data, aes(x = Logged_Salary)) +
  geom_density(fill = "lightgreen", color = "black", alpha = 0.7) +
  labs(title = "Density of Logged Salary", x = "Log Salary", y = "Density") +
  theme_minimal()

# Density plot for Birth Year 
ggplot(hitters_data, aes(x = `Birth Year`)) +
  geom_density(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Density of Birth Year", x = "Birth Year", y = "Density") +
  theme_minimal()

# Density plot for At Bat
ggplot(hitters_data, aes(x = `At Bat`)) +
  geom_density(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Density of At Bat", x = "At Bat", y = "Density") +
  theme_minimal()

```

Both variables are not normally distributed, so we cannot run tests that assume normality, such as the Shapiro-Wilk test or Q-Q plots.
Instead, we would use the Pearson Correlation test.

### Pearson Correlation heatmap

```{r, echo=FALSE}
#Compute Pearson correlation
numeric_filtered_data <- hitters_data[sapply(hitters_data, is.numeric)]
cor_matrix <- cor(numeric_filtered_data, method = "pearson")



ggcorrplot(cor_matrix, lab = TRUE, type = "lower", title = "Pearson Correlation Heatmap")

```

### Scatterplots 

### Assumption tests

## Conclusions 

## Main Observations 

## Future Directions


